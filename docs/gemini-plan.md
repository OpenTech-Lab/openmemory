# ğŸ§  Mnemonic Link

**Mnemonic Link** is a unified, cross-platform AI memory layer. It allows multiple AI agents and tools to share a persistent local database, ensuring your context follows you regardless of which LLM you are using.

Built with **Rust** for performance and **MCP** for seamless integration, it moves beyond basic RAG by utilizing a keyword-indexed retrieval system that prioritizes relevance over volume.

---

## ğŸ—ï¸ System Architecture

### The Tech Stack

* **Monorepo:** Turborepo
* **Backend:** Rust (Axum/Poise)
* **Search Engine:** OpenSearch (Keyword & BM25 indexing)
* **Database:** PostgreSQL (Relational metadata & long-term storage)
* **Frontend:** Next.js 14, Tailwind CSS, shadcn/ui
* **Protocol:** Model Context Protocol (MCP)
* **Containerization:** Docker Compose

---

## ğŸ”¬ The Memory Algorithm: "Anchor & Expand"

To avoid the "Token Tax" of traditional RAG, Mnemonic Link uses a hybrid approach based on **Information Foraging Theory**.

### 1. Hybrid Indexing

Every message is processed through a dual-pipeline:

* **Global Keywords:** Extracted using Rust-based NLP to create an inverted index in OpenSearch.
* **Semantic Vector:** A lightweight embedding for "vibe" matching.

### 2. Retrieval Logic (The Formula)

Instead of returning the top  chunks, we calculate a **Relevance Score ():**

Where:

* **Step A (Search):** Use OpenSearch to find the most important "Anchor" keywords.
* **Step B (Pinpoint):** Identify the specific timestamp of the "Correct Part."
* **Step C (Extract):** Retrieve the **entire conversation block** surrounding that timestamp from PostgreSQL, providing the AI with full context without irrelevant noise.

---

## ğŸš€ Getting Started

### Prerequisites

* Docker & Docker Compose
* Node.js (pnpm recommended)
* Rust (Cargo)

### Development Setup

This project uses **Turborepo** to manage the frontend and backend simultaneously.

1. **Clone the repo:**
```bash
git clone https://github.com/your-repo/mnemonic-link.git
cd mnemonic-link

```


2. **Install dependencies:**
```bash
pnpm install

```


3. **Spin up the infrastructure:**
```bash
docker-compose up -d
# This starts PostgreSQL and OpenSearch

```


4. **Run in Dev Mode:**
```bash
pnpm dev

```



---

## ğŸ› ï¸ Usage

1. **Launch the Dashboard:** Navigate to `localhost:3000`. Here you can toggle the "Memory Active" switch to control when the AI should recall data.
2. **Connect to AI Tool:** Add the local MCP server endpoint (generated by the Rust backend) to your AI tool (e.g., Claude Desktop or an MCP-compatible IDE).
3. **Chat & Store:** As you talk to your AI, Mnemonic Link intercepts (if active), indexes the data, and provides the "Search" tool to the AI.
4. **Recall:** The AI will automatically call the `search_memory` tool using specific keywords before responding to complex queries.

---

## ğŸ“‚ Repository Structure

```text
.
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ web/          # Next.js + shadcn/ui frontend
â”‚   â””â”€â”€ server/       # Rust MCP server + API
â”œâ”€â”€ packages/
â”‚   â”œâ”€â”€ database/     # Prisma/SQL schemas
â”‚   â””â”€â”€ config/       # Shared TS/Rust configs
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ turbo.json
â””â”€â”€ README.md

```

---

## ğŸ›¡ï¸ Privacy & Control

* **Local First:** All data stays on your machine in the Docker volume.
* **Active Switch:** A global "Recall Toggle" in the UI allows you to go "Off the Record," preventing the MCP server from returning any memory results to the AI.
